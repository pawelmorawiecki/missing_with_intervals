{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.impute import SimpleImputer  # used to input missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fd7f4020bd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "MISSING_SQUARE = 13 #size of missing square\n",
    "IMAGE_SHAPE = (28,28)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = datasets.MNIST(\"./\", train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = datasets.MNIST(\"./\", train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros(len(mnist_train))\n",
    "for i in range(len(mnist_train)): labels[i] = mnist_train[i][1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_nan = (mnist_train.data.numpy()/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create missing squares at random positions\n",
    "mask = np.zeros((len(mnist_train), IMAGE_SHAPE[0], IMAGE_SHAPE[1]))\n",
    "for z in range(len(mask)):\n",
    "    x_position = randint(0,IMAGE_SHAPE[0]-MISSING_SQUARE)\n",
    "    y_position = randint(0,IMAGE_SHAPE[1]-MISSING_SQUARE)\n",
    "    for i in range(x_position,x_position+MISSING_SQUARE):\n",
    "        for j in range(y_position,y_position+MISSING_SQUARE):\n",
    "            mask[z][i][j] = 1\n",
    "            data_with_nan[z][i][j] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple imputation\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "imp.fit(data_with_nan.reshape((60000,784)))\n",
    "data_after_imputation = imp.transform(data_with_nan.reshape((60000,784)))\n",
    "data_after_imputation = data_after_imputation.reshape((60000,1,28,28)) #back to (28,28) shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to files\n",
    "np.save('./data/MNIST_data_imputation.npy', data_after_imputation)\n",
    "np.save('./data/MNIST_labels.npy', labels)\n",
    "np.save('./data/MNIST_mask.npy', mask.reshape((60000,1,28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.zeros(len(mnist_test))\n",
    "for i in range(len(mnist_test)): test_labels[i] = mnist_test[i][1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_with_nan = (mnist_test.data.numpy()/255.0)\n",
    "\n",
    "# create missing squares at random positions\n",
    "test_mask = np.zeros((len(mnist_test), IMAGE_SHAPE[0], IMAGE_SHAPE[1]))\n",
    "for z in range(len(test_mask)):\n",
    "    x_position = randint(0,IMAGE_SHAPE[0]-MISSING_SQUARE)\n",
    "    y_position = randint(0,IMAGE_SHAPE[1]-MISSING_SQUARE)\n",
    "    for i in range(x_position,x_position+MISSING_SQUARE):\n",
    "        for j in range(y_position,y_position+MISSING_SQUARE):\n",
    "            test_mask[z][i][j] = 1\n",
    "            test_data_with_nan[z][i][j] = np.nan\n",
    "\n",
    "test_mask = test_mask.reshape((10000,1,28,28))\n",
    "\n",
    "test_data_after_imputation = imp.transform(test_data_with_nan.reshape((10000,784)))\n",
    "test_data_after_imputation = test_data_after_imputation.reshape((10000,1,28,28)) #back to (28,28) shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to files\n",
    "np.save('./data/MNIST_test_data_imputation.npy', test_data_after_imputation)\n",
    "np.save('./data/MNIST_test_labels.npy', test_labels)\n",
    "np.save('./data/MNIST_test_mask.npy', test_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MISSING_SQUARE = 13 #size of missing square\n",
    "IMAGE_SHAPE = (32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar_train = datasets.CIFAR10(\"./\", train=True, download=True, transform=transforms.ToTensor())\n",
    "cifar_test = datasets.CIFAR10(\"./\", train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros(len(cifar_train))\n",
    "for i in range(len(cifar_train)): labels[i] = cifar_train[i][1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_nan = (cifar_train.data/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create missing squares at random positions\n",
    "mask = np.zeros((len(cifar_train), IMAGE_SHAPE[0], IMAGE_SHAPE[1], 3))\n",
    "for z in range(len(mask)):\n",
    "    x_position = randint(0,IMAGE_SHAPE[0]-MISSING_SQUARE)\n",
    "    y_position = randint(0,IMAGE_SHAPE[1]-MISSING_SQUARE)\n",
    "    \n",
    "    for c in range(3): #loop over channels\n",
    "        for i in range(x_position,x_position+MISSING_SQUARE):\n",
    "            for j in range(y_position,y_position+MISSING_SQUARE):\n",
    "                mask[z][i][j][c] = 1\n",
    "                data_with_nan[z][i][j][c] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple imputation\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "imp.fit(data_with_nan.reshape((len(cifar_train),32*32*3)))\n",
    "data_after_imputation = imp.transform(data_with_nan.reshape((len(cifar_train),32*32*3)))\n",
    "data_after_imputation = data_after_imputation.reshape((len(cifar_train),32,32,3)) #back to (32,32) shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to files\n",
    "np.save('./data/CIFAR_data_imputation.npy', data_after_imputation)\n",
    "np.save('./data/CIFAR_labels.npy', labels)\n",
    "np.save('./data/CIFAR_mask.npy', mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.zeros(len(cifar_test))\n",
    "for i in range(len(cifar_test)): test_labels[i] = cifar_test[i][1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_with_nan = (cifar_test.data/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create missing squares at random positions\n",
    "test_mask = np.zeros((len(cifar_test), IMAGE_SHAPE[0], IMAGE_SHAPE[1], 3))\n",
    "for z in range(len(test_mask)):\n",
    "    x_position = randint(0,IMAGE_SHAPE[0]-MISSING_SQUARE)\n",
    "    y_position = randint(0,IMAGE_SHAPE[1]-MISSING_SQUARE)\n",
    "    \n",
    "    for c in range(3): #loop over channels\n",
    "        for i in range(x_position,x_position+MISSING_SQUARE):\n",
    "            for j in range(y_position,y_position+MISSING_SQUARE):\n",
    "                test_mask[z][i][j][c] = 1\n",
    "                test_data_with_nan[z][i][j][c] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_after_imputation = imp.transform(test_data_with_nan.reshape((len(cifar_test),32*32*3)))\n",
    "test_data_after_imputation = test_data_after_imputation.reshape((len(cifar_test),32,32,3)) #back to (32,32) shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving to files\n",
    "np.save('./data/CIFAR_test_data_imputation.npy', test_data_after_imputation)\n",
    "np.save('./data/CIFAR_test_labels.npy', test_labels)\n",
    "np.save('./data/CIFAR_test_mask.npy', test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
